<!DOCTYPE html>
<html>
<head>
  <title>MedBot Vision & Voice Test</title>
  <style>
    body { font-family: Arial; max-width: 800px; margin: 50px auto; padding: 20px; }
    #chat { border: 1px solid #ccc; height: 400px; overflow-y: auto; padding: 20px; margin: 20px 0; }
    .message { margin: 10px 0; padding: 10px; border-radius: 10px; }
    .user { background: #007bff; color: white; margin-left: 20%; }
    .assistant { background: #f1f3f4; margin-right: 20%; }
    input, textarea, button { padding: 10px; margin: 5px; border: 1px solid #ddd; border-radius: 5px; }
    #imagePreview { max-width: 200px; max-height: 200px; margin: 10px 0; }
    #replyAudio { margin: 10px 0; }
  </style>
</head>
<body>
  <h1>ü©∫ MedBot Vision & Voice Test</h1>
  
  <div>
    <label>üì∑ Image (optional):</label>
    <input type="file" id="imageInput" accept="image/*">
    <img id="imagePreview" style="display:none;">
  </div>
  
  <textarea id="messageInput" placeholder="Speak or type your question..." rows="3"></textarea>
  <br>
  <select id="language">
      <option value="en">English</option>
      <option value="es">Espa√±ol</option>
      <option value="fr">Fran√ßais</option>
      <option value="de">Deutsch</option>
      <option value="hi">Hindi</option>
      <option value="ar">Arabic</option>
  </select>
  <br>
  <button onclick="sendVisionMessage()">Send to MedBot (Image + Text)</button>
  <button onclick="sendTextMessage()">Text Only</button>
  <button id="voiceBtn">üéôÔ∏è Record Voice</button>
  <audio id="replyAudio" controls style="display:none;"></audio>
  
  <div id="chat"></div>

  <script>
    const TOKEN = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjY5MjlmMzkxZWQwNTY5MGI4NTk3NzY4ZSIsImVtYWlsIjoidGVzdEBleGFtcGxlLmNvbSIsImlhdCI6MTc2NDM1NzAwOSwiZXhwIjoxNzY0OTYxODA5fQ.iNb72y4X9e4bFEKlMr1UslI8SZzXMxQdUBWcEM4Qeug';
    const API_BASE = 'http://localhost:5000/api';

    let imageBase64 = null;
    let mediaRecorder = null;
    let stream = null;
    let isRecording = false;
    let audioChunks = [];
    const replyAudio = document.getElementById('replyAudio');

    // ---------- Image handling ----------
    document.getElementById('imageInput').addEventListener('change', (e) => {
      const file = e.target.files[0];
      if (file) {
        const reader = new FileReader();
        reader.onload = (e2) => {
          imageBase64 = e2.target.result.split(',')[1];
          const img = document.getElementById('imagePreview');
          img.src = e2.target.result;
          img.style.display = 'block';
        };
        reader.readAsDataURL(file);
      }
    });

    function addMessage(content, sender) {
      const chat = document.getElementById('chat');
      const div = document.createElement('div');
      div.className = `message ${sender}`;
      div.innerHTML = `<strong>${sender}:</strong> ${content}`;
      chat.appendChild(div);
      chat.scrollTop = chat.scrollHeight;
    }

    // ---------- Text + Vision ----------
    async function sendVisionMessage() {
      if (!imageBase64) {
        alert('Please select an image first!');
        return;
      }
      const message = document.getElementById('messageInput').value.trim();
      const language = document.getElementById('language').value;

      addMessage(message || '[Image]', 'user');

      try {
        const res = await fetch(`${API_BASE}/chat/vision`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${TOKEN}`
          },
          body: JSON.stringify({
            imageBase64,
            mimeType: 'image/jpeg',
            message,
            language
          })
        });

        const data = await res.json();
        if (data.messages && data.messages[1]) {
          addMessage(data.messages[1].content, 'assistant');
        }

        if (data.audioBase64) {
          playAudio(data.audioBase64, data.audioMimeType || 'audio/wav');
        }
      } catch (err) {
        addMessage('Error: ' + err.message, 'assistant');
      }
    }

    async function sendTextMessage() {
      const message = document.getElementById('messageInput').value.trim();
      if (!message) return;

      addMessage(message, 'user');

      try {
        const res = await fetch(`${API_BASE}/chat`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${TOKEN}`
          },
          body: JSON.stringify({ message })
        });

        const data = await res.json();
        if (data.messages && data.messages[1]) {
          addMessage(data.messages[1].content, 'assistant');
        }

        if (data.audioBase64) {
          playAudio(data.audioBase64, data.audioMimeType || 'audio/wav');
        }
      } catch (err) {
        addMessage('Error: ' + err.message, 'assistant');
      }
    }

    function playAudio(base64, mimeType) {
      const replyBlob = b64ToBlob(base64, mimeType);
      const url = URL.createObjectURL(replyBlob);
      replyAudio.src = url;
      replyAudio.style.display = 'block';
      replyAudio.play();
    }

    // ---------- Voice recording -> STT ----------
    const voiceBtn = document.getElementById('voiceBtn');

    voiceBtn.onclick = async () => {
      if (!isRecording) {
        try {
          console.log('üé§ Starting recording...');
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
          audioChunks = [];

          mediaRecorder.ondataavailable = (e) => {
            if (e.data.size > 0) {
              audioChunks.push(e.data);
              console.log('üì¶ Audio chunk received:', e.data.size);
            }
          };

          mediaRecorder.onstop = async () => {
            console.log('‚èπÔ∏è Recording stopped, sending to STT...');
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            console.log('üéµ Final blob size:', audioBlob.size);
            await sendVoiceForTranscription(audioBlob);

            if (stream) {
              stream.getTracks().forEach(track => track.stop());
            }
            stream = null;
            mediaRecorder = null;
          };

          mediaRecorder.start();
          isRecording = true;
          voiceBtn.textContent = '‚èπÔ∏è Stop Recording';
          voiceBtn.style.background = '#dc3545';
        } catch (err) {
          console.error('üé§ Microphone error:', err);
          alert('Microphone access denied or not available.');
        }
      } else {
        console.log('üõë User stopped recording');
        mediaRecorder.stop();
        isRecording = false;
        voiceBtn.textContent = 'üéôÔ∏è Record Voice';
        voiceBtn.style.background = '';
      }
    };

    async function sendVoiceForTranscription(blob) {
      console.log('üöÄ Sending to /voice/transcribe...');
      console.log('Blob size:', blob.size);

      const formData = new FormData();
      formData.append('audio', blob, 'voice.webm');

      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => {
          console.error('‚è∞ STT request timed out');
          controller.abort();
        }, 15000);

        const res = await fetch(`${API_BASE}/voice/transcribe`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${TOKEN}`
          },
          body: formData,
          signal: controller.signal
        });

        clearTimeout(timeoutId);
        console.log('‚úÖ Response received:', res.status, res.ok);

        const textBody = await res.text();
        console.log('üì¶ Raw body:', textBody);

        let data;
        try {
          data = JSON.parse(textBody);
        } catch (e) {
          console.error('‚ùå JSON parse failed:', e);
          addMessage('Transcription parse error', 'assistant');
          return;
        }

        console.log('üìù Parsed data:', data);

        if (data.text) {
          const cleanText = data.text.trim();
          document.getElementById('messageInput').value = cleanText;
          addMessage(`üé§ (Voice) ${cleanText}`, 'user');
          console.log('‚úÖ Textarea updated with:', cleanText);
        } else {
          addMessage('No transcription returned.', 'assistant');
        }
      } catch (err) {
        console.error('‚ùå STT Error:', err.name, err.message);
        addMessage('Voice transcription failed: ' + err.message, 'assistant');
      }
    }

    function b64ToBlob(b64Data, contentType) {
      const byteChars = atob(b64Data);
      const byteArrays = [];
      for (let offset = 0; offset < byteChars.length; offset += 512) {
        const slice = byteChars.slice(offset, offset + 512);
        const byteNumbers = new Array(slice.length);
        for (let i = 0; i < slice.length; i++) {
          byteNumbers[i] = slice.charCodeAt(i);
        }
        byteArrays.push(new Uint8Array(byteNumbers));
      }
      return new Blob(byteArrays, { type: contentType });
    }
  </script>
</body>
</html>
